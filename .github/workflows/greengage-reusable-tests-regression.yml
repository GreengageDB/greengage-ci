name: Greengage Reusable Regression Tests on GitHub

# Environment variables
env:
  COMPOSE_HTTP_TIMEOUT: 400
  DOCKER_COMPOSE: "docker compose"

# Trigger for reusable workflow
on:
  workflow_call:
    inputs:
      version:
        description: 'Greengage version (e.g., 6 or 7)'
        required: true
        type: string
      target_os:
        description: 'Target OS for build (e.g., ubuntu, centos, rockylinux)'
        required: true
        type: string
      target_os_version:
        description: 'Target OS version (e.g., 22, 7, 8)'
        required: false
        type: string
        default: ''
      python3:
        description: 'Python3 build argument (ignored)'
        required: false
        type: string
        default: ''
    secrets:
      ghcr_token:
        description: 'GitHub token for GHCR access'
        required: true

jobs:
  optimizer:  # Regression tests
    runs-on: ubuntu-latest
    timeout-minutes: 180
    strategy:
      fail-fast: false
      matrix:
        optimizer: [orca, postgres]
    permissions:
      contents: read  # Explicit for default behavior
      packages: read  # Explicit for GHCR access clarity
      actions: write  # Required for cache and artifact upload
    steps:
      # Restore SHA image from cache
      - name: Restore SHA image from cache
        uses: actions/cache/restore@v4
        with:
          path: ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}_${{ github.sha }}.tar
          key: ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}_${{ github.sha }}

      # Load SHA image
      - name: Load SHA image
        run: |
          docker load < ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}_${{ github.sha }}.tar
          rm -f ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}_${{ github.sha }}.tar

      # Maximize build space for Docker
      - name: Move /var/lib/docker/
        run: sudo mv /var/lib/docker/ "${GITHUB_WORKSPACE}/docker"

      - name: Maximize build space
        uses: easimon/maximize-build-space@master
        with:
          root-reserve-mb: 512
          temp-reserve-mb: 32
          swap-size-mb: 32
          remove-dotnet: 'true'
          remove-android: 'true'
          remove-haskell: 'true'
          remove-codeql: 'true'
          remove-docker-images: 'false'
          build-mount-path: '/var/lib/docker/'

      - name: Restore /var/lib/docker/
        run: sudo sh -c "mv ${GITHUB_WORKSPACE}/docker/* /var/lib/docker"

      # Checkout repository with shallow clone
      - name: Checkout Greengage repo
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ github.event.pull_request.head.sha || github.ref }}
          submodules: recursive

      # Run Regression tests
      - name: Regression test with Optimizer ${{ matrix.optimizer }}
        env:
          ARCH: 'x86-64'
          LOG_DIR: '/var/lib/docker/logs_${{ matrix.optimizer }}'
          LOG_NAME: '${{ matrix.optimizer }}'
          LOG_EXTENSION: 'pg_log'
          IMAGE: ghcr.io/${{ github.repository }}/ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}:${{ github.sha }}
          CONT_NAME: ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}_optimizer_${{ matrix.optimizer}}
        run: |
          export IMAGE=${IMAGE,,}
          cat > regression_optimizer_${{ matrix.optimizer }}.bash << EOF
          set -x
          cd /home/gpadmin/
          ssh-keygen -A
          /usr/sbin/sshd
          EXIT_CODE=0
          bash gpdb_src/concourse/scripts/ic_gpdb.bash || EXIT_CODE=1
          echo "Script gpdb_src/concourse/scripts/ic_gpdb.bash finished with \$EXIT_CODE"
          for dir in results regression.diffs ${LOG_EXTENSION} ; do
            find gpdb_src/src/test/ -name "$dir" -type d -exec tar -rf /logs/${LOG_NAME}_${ARCH}_$dir.tar "{}" \;
          done
          echo "Debug find LOG_EXTENSION=$LOG_EXTENSION"
          find gpdb_src/gpAux/gpdemo/datadirs/ -name "*" -type d | tee /logs/log_dirs
          find gpdb_src/gpAux/gpdemo/datadirs/ -name "$LOG_EXTENSION" -type d -exec tar -rf /logs/${LOG_NAME}_${ARCH}_$dir.tar "{}" \;
          tar -cf /logs/${LOG_NAME}_${ARCH}_gpAdminLogs.tar gpAdminLogs/
          tar -cf /logs/${LOG_NAME}_${ARCH}_gpAux.tar gpdb_src/gpAux/gpdemo/datadirs/gpAdminLogs/
          exit \$EXIT_CODE
          EOF

          # Run tests and save logs to a volume
          docker run -i --name $CONT_NAME \
            -v $LOG_DIR:/logs \
            -e TEST_OS='${{ inputs.target_os }}' \
            -e MAKE_TEST_COMMAND="-k PGOPTIONS='-c optimizer=${{ matrix.optimizer == 'orca' && 'on' || 'off' }}' installcheck-world" \
            --sysctl 'kernel.sem=500 1024000 200 4096' \
            $IMAGE \
            /bin/bash < ./regression_optimizer_${{ matrix.optimizer }}.bash
          status=$?

          # Debug: exit code
          echo "Exit code: '$status'"
          echo "Logs saved to $LOG_DIR"
          ls -lah $LOG_DIR
          exit ${status:-1} # error if not known

      # Upload regression artifacts
      - name: Upload regression artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression_optimizer_${{ matrix.optimizer }}
          path: /var/lib/docker/logs_${{ matrix.optimizer }}
          retention-days: 7
          if-no-files-found: warn  # Warning if no artifacts are found
