name: Greengage Reusable Resource Groups Tests

# Environment variables
env:
  CI_REPO: GreengageDB/greengage-ci
  CI_PATH: .ci
  COMPOSE_HTTP_TIMEOUT: 400
  DOCKER_COMPOSE: "docker compose"

# Trigger for reusable workflow
on:
  workflow_call:
    inputs:
      version:
        description: 'Greengage version (e.g., 6 or 7)'
        required: true
        type: string
      target_os:
        description: 'Target OS for build (e.g., ubuntu, centos, rockylinux)'
        required: true
        type: string
      target_os_version:
        description: 'Target OS version (e.g., 22, 7, 8)'
        required: true
        type: string
      python3:
        description: 'Python3 build argument (ignored)'
        required: false
        type: string
        default: ''
      ref:
        description: 'Branch or ref to checkout'
        required: false
        type: string
    secrets:
      ghcr_token:
        description: 'GitHub token for GHCR access'
        required: true

jobs:
  setup:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    outputs:
      build_version: ${{ steps.set_tag.outputs.build_version }}
    steps:
      # Checkout repository with specified ref or default
      - name: Checkout Greengage repo
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ inputs.ref || github.ref }}
          submodules: recursive
          fetch-depth: 0

      # Set up Docker Compose using docker/setup-compose-action
      - name: Set up Docker Compose
        uses: docker/setup-compose-action@v1

      # Login to GitHub Container Registry
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.ghcr_token }}

      # Determine image tags
      - name: Determine image tags
        id: set_tag
        run: |
          SHORT_SHA=$(git rev-parse --short HEAD)
          VERSION=$(git describe --tags --abbrev=0 2>/dev/null | sed 's/\//_/g')
          echo "sha_tag=$SHORT_SHA" >> $GITHUB_OUTPUT
          echo "build_version=$VERSION" >> $GITHUB_OUTPUT
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            SAFE_BRANCH=$(echo ${{ github.head_ref }} | sed 's/[^a-zA-Z0-9._-]/_/g')
            echo "branch_tag=$SAFE_BRANCH" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" =~ ^refs/tags/ ]]; then
            echo "version_tag=$VERSION" >> $GITHUB_OUTPUT
          fi

  resgroup:
    runs-on: self-hosted
    needs: setup
    permissions:
      contents: read
      packages: read
    steps:
      # - name: Move /var/lib/docker/
      #   run: sudo mv /var/lib/docker/ "${GITHUB_WORKSPACE}/docker"

      # - name: Maximize build space
      #   uses: easimon/maximize-build-space@master
      #   with:
      #     root-reserve-mb: 512
      #     temp-reserve-mb: 32
      #     swap-size-mb: 32
      #     remove-dotnet: 'true'
      #     remove-android: 'true'
      #     remove-haskell: 'true'
      #     remove-codeql: 'true'
      #     remove-docker-images: 'false'
      #     build-mount-path: '/var/lib/docker/'

      # - name: Restore /var/lib/docker/
      #   run: sudo sh -c "mv ${GITHUB_WORKSPACE}/docker/* /var/lib/docker"

      # - name: Set up Docker Compose
      #   uses: docker/setup-compose-action@v1

      - name: Check CGroups Version
        run: |
          cgroups_version=$(docker info --format '{{.CgroupVersion}}')
          echo  -en "CGroups v$cgroups_version detected "
          if [ $cgroups_version -ne 1 ] ; then
            echo  "but v1 required. Exiting"; exit 1
          else
            echo  "as expected. Go on"
          fi
      - name: Checkout Greengage repo
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ inputs.ref || github.ref }}
          submodules: recursive
          # fetch-depth: 0

      - name: Create CI directory
        run: mkdir -p ${{ env.CI_PATH }}
      - name: Checkout remote CI repo
        id: checkout_remote_ci
        uses: actions/checkout@v4
        continue-on-error: true
        with:
          repository: ${{ env.CI_REPO }}
          path: ${{ env.CI_PATH }}
      - name: Fallback to ci directory if remote fails
        if: steps.checkout_remote_ci.outcome != 'success'
        run: |
          if [ -d "ci" ]; then
            ln -s $(pwd)/ci ${{ env.CI_PATH }}
          else
            echo "Error: Neither remote CI repo (${{ env.CI_REPO }}) nor local ci directory found, cannot proceed."
            exit 1

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.ghcr_token }}

      # # Create allure-results directory
      # - name: Create allure-results directory
      #   run: |
      #     rm -rf allure-results
      #     mkdir -p allure-results -m 777

      # Generate SSH keys
      - name: Generate SSH keys
        run: |
          mkdir -p ssh_keys
          if [ ! -e "ssh_keys/id_rsa" ]; then
            ssh-keygen -P "" -f ssh_keys/id_rsa
          fi
      - name: Run Resource groups tests
        env:
          IMAGE: ghcr.io/${{ github.repository }}/ggdb${{ inputs.version }}_${{ inputs.target_os }}${{ inputs.target_os_version }}:${{ needs.setup.outputs.build_version }}
          PROJECT: resgroup
          SERVICES: "cdw sdw1"
        run: |
          ## Initialize containers START
          set -ex -o pipefail
          # Detect&Down all working Docker composes
          .ci/scripts/docker_compose_down.sh
          # Start containers using existing volumes from ci/docker-compose.yaml
          $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml --env-file ci/.env up -d
          services=${SERVICES:-$($DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml config --services | tr '\n' ' ')}

          # Prepare ALL containers first
          for service in $services
          do
            $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -T \
              $service bash -c "mkdir -p /data/gpdata && chmod -R 777 /data &&
                source gpdb_src/concourse/scripts/common.bash && install_gpdb &&
                ./gpdb_src/concourse/scripts/setup_gpadmin_user.bash &&
                mkdir -p /logs/$service" &
          done
          wait

          # Add host keys to known_hosts after containers setup
          for service in $services
          do
            $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -T \
              $service bash -c "ssh-keyscan ${services/$service/} >> /home/gpadmin/.ssh/known_hosts" &
          done
          wait
          ## Initialize containers END

          ## Grant access rights to group controllers
          for service in $services
          do
            $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -T \
              $service bash -c "
              chmod -R 777 /sys/fs/cgroup/{memory,cpu,cpuset} &&
              mkdir /sys/fs/cgroup/{memory,cpu,cpuset}/gpdb &&
              chmod -R 777 /sys/fs/cgroup/{memory,cpu,cpuset}/gpdb &&
              chown -R gpadmin:gpadmin /sys/fs/cgroup/{memory,cpu,cpuset}/gpdb
              "
          done

          ## Create cluster
          # Extract HOSTS_LIST from SERVICES (remove first word)
          HOSTS_LIST="${SERVICES#* }"
          $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -T cdw \
            bash -c "source gpdb_src/concourse/scripts/common.bash && HOSTS_LIST='$HOSTS_LIST' make_cluster"

          ## Run Resource groups tests
          # Disable exit on error to allow log collection
          set +e
          # Run tests
          $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -Tu gpadmin cdw bash -ex <<EOF
            source /usr/local/greengage-db-devel/greengage_path.sh
            source gpdb_src/gpAux/gpdemo/gpdemo-env.sh
            export LDFLAGS="-L\${GPHOME}/lib"
            export CPPFLAGS="-I\${GPHOME}/include"
            export USER=gpadmin

            cd /home/gpadmin/gpdb_src
            ./configure --prefix=/usr/local/greengage-db-devel \
                --without-zlib --without-rt --without-libcurl \
                --without-libedit-preferred --without-docdir --without-readline \
                --disable-gpcloud --disable-gpfdist --disable-orca \
                ${CONFIGURE_FLAGS}

            make -C /home/gpadmin/gpdb_src/src/test/regress
            ssh sdw1 mkdir -p /home/gpadmin/gpdb_src/src/test/{regress,isolation2} </dev/null
            scp /home/gpadmin/gpdb_src/src/test/regress/regress.so \
                gpadmin@sdw1:/home/gpadmin/gpdb_src/src/test/regress/

            make PGOPTIONS="-c optimizer=off -c statement_mem=125MB" installcheck-resgroup || (
                errcode=\$?
                find src/test/isolation2 -name regression.diffs \
                | while read diff; do
                    cat <<EOF1

          ======================================================================
          DIFF FILE: \$diff
          ----------------------------------------------------------------------

          EOF1
                    cat \$diff
                  done
                exit \$errcode
            )
          EOF

          exitcode=$?

          # Define unified log paths and destinations
          LOG_PATHS=(
            "gpAdminLogs"
            "gpdb_src/gpAux/gpdemo/datadirs/gpAdminLogs"
            "gpdb_src/gpAux/gpdemo/datadirs/qddir/demoDataDir-1/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/standby/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast1/demoDataDir0/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast2/demoDataDir1/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast3/demoDataDir2/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast_mirror1/demoDataDir0/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast_mirror2/demoDataDir1/pg_log"
            "gpdb_src/gpAux/gpdemo/datadirs/dbfast_mirror3/demoDataDir2/pg_log"
            "gpdb_src/src/test/isolation2/results/resgroup"
            "gpdb_src/src/test/isolation2/regression.diffs"
          )

          # Copy logs from services to mounted external volumes
          for service in $SERVICES ; do
            $DOCKER_COMPOSE -p $PROJECT -f ci/docker-compose.yaml exec -T $service bash -ex <<EOF
            cd /home/gpadmin
            mkdir -p /logs/$service
            rsync -av --files-from=<(find ${LOG_PATHS[@]} -type d 2>/dev/null) ./ /logs/$service 
          EOF
          done

          # Detect&Down all working Docker composes
          .ci/scripts/docker_compose_down.sh

          # Ensure logs directories are readable
          sudo chown $USER:$USER -R ./

          # Debug: Exit code
          echo "Exit code: $exitcode"
          exit ${exitcode:-1}

      # Sanitize log file names
      - name: Sanitize log file names
        if: always()
        run: |
          find ./logs_cdw ./logs_sdw1 -type f -name '*:*' -exec bash -c 'mv "$1" "${1//:/_}"' _ {} \;
          find ./logs_cdw ./logs_sdw1 -type f -name '*:*' || true  # Debug

      - name: Upload resgroup artifacts
        if: always()  # Run even if previous step fails
        uses: actions/upload-artifact@v4
        with:
          name: resgroup-logs-${{ inputs.target_os }}${{ inputs.target_os_version }}
          path: |
            ./logs_cdw/*
            ./logs_sdw1/*
          retention-days: 7
